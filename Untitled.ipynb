{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc8ed9-20c3-405a-80c9-71bdca38d8be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始处理专利数据 ===\n",
      "开始扫描文件夹: data\n",
      "正在处理文件: 4001-5000.txt...\n",
      "正在处理文件: 5001-6000.txt...\n",
      "正在处理文件: 8001-9000.txt...\n",
      "正在处理文件: 7001-8000.txt...\n",
      "正在处理文件: 9001-10000.txt...\n",
      "正在处理文件: 1-1000.txt...\n",
      "正在处理文件: 2001-3000.txt...\n",
      "正在处理文件: 1001-2000.txt...\n",
      "正在处理文件: 6001-7000.txt...\n",
      "正在处理文件: 11001-11650.txt...\n",
      "正在处理文件: 3001-4000.txt...\n",
      "正在处理文件: 10001-11000.txt...\n",
      "完成处理! 共处理 12 个文件，11650 个专利数据块\n",
      "结果已保存到: data-results\n",
      "\n",
      "=== 开始分析引用网络 ===\n",
      "节点指标已保存到: data-results\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 导入GPU加速库\n",
    "import cupy as cp\n",
    "from cupyx.scipy import sparse\n",
    "import cudf\n",
    "\n",
    "class PatentProcessor:\n",
    "    def __init__(self):\n",
    "        self.families = []\n",
    "        self.citations = []\n",
    "        self.seen_hashes = set()\n",
    "        # GPU内存中的数据结构\n",
    "        self.citation_matrix = None\n",
    "        self.patent_indices = {}\n",
    "    \n",
    "    def _is_valid_patent(self, patent_str):\n",
    "        return bool(re.match(\n",
    "            r'^[A-Z]{2}\\d+[-][A-Z]?\\d*$|^[A-Z]{2}\\d+[-][A-Z]\\d*[-][A-Z]\\d+$',\n",
    "            patent_str))\n",
    "    \n",
    "    def process_folder(self, input_folder, output_folder):\n",
    "        \"\"\"主处理流程\"\"\"\n",
    "        print(f\"开始扫描文件夹: {input_folder}\")\n",
    "        file_count = 0\n",
    "        processed_blocks = 0\n",
    "        \n",
    "        for filename in os.listdir(input_folder):\n",
    "            if not filename.endswith('.txt'):\n",
    "                continue\n",
    "            file_count += 1\n",
    "            filepath = os.path.join(input_folder, filename)\n",
    "            print(f\"正在处理文件: {filename}...\")\n",
    "            processed_blocks += self._process_file(filepath)\n",
    "        \n",
    "        print(f\"完成处理! 共处理 {file_count} 个文件，{processed_blocks} 个专利数据块\")\n",
    "        \n",
    "        # 构建GPU加速的引用矩阵\n",
    "        self._build_citation_matrix()\n",
    "        \n",
    "        self._save_results(output_folder)\n",
    "    \n",
    "    def _process_file(self, filepath):\n",
    "        \"\"\"处理单个文件\"\"\"\n",
    "        block_count = 0\n",
    "        current_block = []\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            for line in f:\n",
    "                line = line.rstrip('\\n')\n",
    "                if line.startswith('PT '):\n",
    "                    current_block = [line]\n",
    "                elif line.startswith('ER'):\n",
    "                    current_block.append(line)\n",
    "                    self._parse_block('\\n'.join(current_block))\n",
    "                    block_count += 1\n",
    "                    current_block = []\n",
    "                elif current_block:\n",
    "                    current_block.append(line)\n",
    "        return block_count\n",
    "    \n",
    "    def _parse_block(self, block_text):\n",
    "        \"\"\"解析单个专利数据块\"\"\"\n",
    "        block_hash = hash(block_text.strip())\n",
    "        if block_hash in self.seen_hashes:\n",
    "            return\n",
    "        self.seen_hashes.add(block_hash)\n",
    "        \n",
    "        try:\n",
    "            family, citations = self._extract_relations(block_text)\n",
    "            self.families.append(family)\n",
    "            self.citations.extend(citations)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 解析失败: {str(e)}\\n片段预览: {block_text[:150]}...\")\n",
    "    \n",
    "    def _build_citation_matrix(self):\n",
    "    # 创建专利ID到索引的映射\n",
    "     all_patents = set()\n",
    "     for cite in self.citations:\n",
    "        all_patents.add(cite['source'])\n",
    "        all_patents.add(cite['target'])\n",
    "        \n",
    "     self.patent_indices = {patent: i for i, patent in enumerate(all_patents)}\n",
    "     num_patents = len(all_patents)\n",
    "    \n",
    "    # 构建COO格式的稀疏矩阵\n",
    "     rows = []\n",
    "     cols = []\n",
    "     data = []\n",
    "    \n",
    "     for cite in self.citations:\n",
    "        source_idx = self.patent_indices.get(cite['source'])\n",
    "        target_idx = self.patent_indices.get(cite['target'])\n",
    "        \n",
    "        if source_idx is not None and target_idx is not None:\n",
    "            rows.append(target_idx)  # 被引专利作为行\n",
    "            cols.append(source_idx)  # 施引专利作为列\n",
    "            data.append(1)\n",
    "    \n",
    "    # 将数据类型转换为float32（CuPy稀疏矩阵支持的类型）\n",
    "     gpu_data = cp.array(data, dtype=cp.float32)\n",
    "     gpu_rows = cp.array(rows, dtype=cp.int32)\n",
    "     gpu_cols = cp.array(cols, dtype=cp.int32)\n",
    "    \n",
    "    # 转换为GPU上的稀疏矩阵\n",
    "     self.citation_matrix = sparse.coo_matrix(\n",
    "        (gpu_data, (gpu_rows, gpu_cols)),\n",
    "        shape=(num_patents, num_patents)\n",
    "     ).tocsr()\n",
    "    \n",
    "    def _save_results(self, output_folder):\n",
    "        \"\"\"保存结果到CSV\"\"\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # 生成家族关系表\n",
    "        family_records = []\n",
    "        for family in self.families:\n",
    "            for member in family['members']:\n",
    "                member_citations = [\n",
    "                    c['target'] for c in self.citations \n",
    "                    if c['source'] == member\n",
    "                ]\n",
    "                family_records.append({\n",
    "                    'PatentFamily': family['family_id'],\n",
    "                    'PatentNumber': member,\n",
    "                    'CitedPatents': ';'.join(member_citations) or ''\n",
    "                })\n",
    "        \n",
    "        # 使用cuDF加速数据处理\n",
    "        if family_records:\n",
    "            family_df = cudf.DataFrame(family_records)\n",
    "            family_path = os.path.join(output_folder, 'patent_families.csv')\n",
    "            family_df.to_csv(family_path)\n",
    "        else:\n",
    "            pd.DataFrame(columns=['PatentFamily', 'PatentNumber', 'CitedPatents']).to_csv(\n",
    "                os.path.join(output_folder, 'patent_families.csv'), index=False\n",
    "            )\n",
    "        \n",
    "        # 生成引用关系表\n",
    "        if self.citations:\n",
    "            citation_df = cudf.DataFrame([{\n",
    "                'SourcePatent': c['source'],\n",
    "                'CitedPatent': c['target']\n",
    "            } for c in self.citations])\n",
    "            citation_path = os.path.join(output_folder, 'citation_relations.csv')\n",
    "            citation_df.to_csv(citation_path)\n",
    "        else:\n",
    "            pd.DataFrame(columns=['SourcePatent', 'CitedPatent']).to_csv(\n",
    "                os.path.join(output_folder, 'citation_relations.csv'), index=False\n",
    "            )\n",
    "        \n",
    "        print(f\"结果已保存到: {output_folder}\")\n",
    "    \n",
    "    def _extract_relations(self, text):\n",
    "        family = {'members': [], 'family_id': None}\n",
    "        citations = []\n",
    "        current_source = None  # 当前处理的源专利\n",
    "        indent_level = 0       # 当前缩进级别\n",
    "        \n",
    "        for line in text.split('\\n'):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            \n",
    "            # 检测字段标识\n",
    "            if not line.startswith(' ') and len(line) >= 2:\n",
    "                field = line[:2].strip()\n",
    "                if field == 'PN':\n",
    "                    family['members'] = [p.strip() for p in re.split(r';\\s*', line[2:].strip()) if self._is_valid_patent(p)]\n",
    "                    family['family_id'] = ';'.join(family['members'])\n",
    "                elif field == 'CP':\n",
    "                    current_source = re.split(r'\\s+', line[2:].strip())[0]\n",
    "                    indent_level = 0\n",
    "                continue\n",
    "            \n",
    "            # 处理引用关系（带缩进分析）\n",
    "            if line.startswith('      '):  # 4空格：被引用专利\n",
    "                if current_source and indent_level == 1:\n",
    "                    target = re.split(r'\\s+', line.strip())[0]\n",
    "                    if self._is_valid_patent(target):\n",
    "                        citations.append({'source': current_source, 'target': target})\n",
    "            elif line.startswith('  '):    # 2空格：次级源专利\n",
    "                new_source = re.split(r'\\s+', line.strip())[0]\n",
    "                if self._is_valid_patent(new_source):\n",
    "                    current_source = new_source\n",
    "                    indent_level = 1\n",
    "\n",
    "        return family, citations\n",
    "    \n",
    "    def build_citation_network(self):\n",
    "        \"\"\"构建反向引用网络（被引 → 施引）\"\"\"\n",
    "        # 如果有GPU矩阵，先转换为CPU可用格式\n",
    "        if self.citation_matrix is not None:\n",
    "            G = nx.DiGraph()\n",
    "            # 将索引映射回专利号\n",
    "            idx_to_patent = {v: k for k, v in self.patent_indices.items()}\n",
    "            \n",
    "            # 从稀疏矩阵构建图\n",
    "            coo = self.citation_matrix.tocoo()\n",
    "            rows, cols = coo.row.get(), coo.col.get()\n",
    "            data = coo.data.get()\n",
    "            \n",
    "            for i in range(len(rows)):\n",
    "                source = idx_to_patent.get(cols[i])\n",
    "                target = idx_to_patent.get(rows[i])\n",
    "                weight = data[i]\n",
    "                \n",
    "                if source and target:\n",
    "                    G.add_edge(target, source, weight=weight)\n",
    "            \n",
    "            return G\n",
    "        \n",
    "        # 传统方式构建网络\n",
    "        G = nx.DiGraph()\n",
    "        citation_map = defaultdict(list)\n",
    "        \n",
    "        for cite in self.citations:\n",
    "            citation_map[cite['target']].append(cite['source'])  # 反向记录\n",
    "        \n",
    "        for target, sources in citation_map.items():\n",
    "            source_counts = defaultdict(int)\n",
    "            for src in sources:\n",
    "                source_counts[src] += 1\n",
    "            \n",
    "            for src, weight in source_counts.items():\n",
    "                G.add_edge(target, src, weight=weight)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def visualize_network(self, G, output_path):\n",
    "        \"\"\"可视化反向引用网络\"\"\"\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # 计算布局\n",
    "        pos = nx.spring_layout(G, k=0.2, iterations=50)\n",
    "        \n",
    "        # 绘制节点（按入度大小调整）\n",
    "        in_degrees = dict(G.in_degree())\n",
    "        node_sizes = [in_degrees[n] * 50 + 10 for n in G.nodes()]\n",
    "        \n",
    "        nx.draw_networkx_nodes(\n",
    "            G, pos,\n",
    "            node_size=node_sizes,\n",
    "            node_color='lightblue',\n",
    "            alpha=0.8\n",
    "        )\n",
    "        \n",
    "        # 绘制边（按权重调整）\n",
    "        edge_widths = [d['weight'] * 0.8 for _, _, d in G.edges(data=True)]\n",
    "        \n",
    "        nx.draw_networkx_edges(\n",
    "            G, pos,\n",
    "            width=edge_widths,\n",
    "            edge_color='gray',\n",
    "            arrowsize=15,\n",
    "            arrowstyle='->'\n",
    "        )\n",
    "        \n",
    "        # 标注高权重边\n",
    "        edge_labels = {\n",
    "            (u, v): d['weight']\n",
    "            for u, v, d in G.edges(data=True)\n",
    "            if d['weight'] > 2\n",
    "        }\n",
    "        nx.draw_networkx_edge_labels(\n",
    "            G, pos,\n",
    "            edge_labels=edge_labels,\n",
    "            font_size=8\n",
    "        )\n",
    "        \n",
    "        plt.title(\"Patent Citation Network (Cited → Citing)\", fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def analyze_networks(self, output_folder):\n",
    "        \"\"\"GPU加速的网络分析\"\"\"\n",
    "        G = self.build_citation_network()\n",
    "        largest_cc = self.get_largest_component(G)\n",
    "        \n",
    "        # 保存网络数据\n",
    "        self.save_network_data(G, largest_cc, output_folder)\n",
    "        \n",
    "        # 计算并保存节点指标\n",
    "        self.save_node_metrics(G, output_folder)\n",
    "        \n",
    "        # 可视化完整网络和最大连通子网\n",
    "        self.visualize_network(G, os.path.join(output_folder, 'full_network.png'))\n",
    "        self.visualize_network(largest_cc, os.path.join(output_folder, 'largest_component.png'))\n",
    "        \n",
    "        # 计算网络统计指标\n",
    "        total_size = len(G.nodes())\n",
    "        component_size = len(largest_cc.nodes())\n",
    "        total_edges = len(G.edges())\n",
    "        component_edges = len(largest_cc.edges())\n",
    "        \n",
    "        # 创建汇总统计DataFrame\n",
    "        summary_stats = pd.DataFrame({\n",
    "            'metric': ['total_size', 'component_size', 'total_edges', 'component_edges', \n",
    "                      'component_size_ratio', 'component_edges_ratio'],\n",
    "            'value': [total_size, component_size, total_edges, component_edges,\n",
    "                     component_size/total_size if total_size > 0 else 0,\n",
    "                     component_edges/total_edges if total_edges > 0 else 0]\n",
    "        })\n",
    "        \n",
    "        # 保存汇总统计到CSV\n",
    "        summary_path = os.path.join(output_folder, 'network_summary_stats.csv')\n",
    "        summary_stats.to_csv(summary_path, index=False)\n",
    "        print(f\"网络汇总统计已保存到: {summary_path}\")\n",
    "        \n",
    "        # 返回统计信息\n",
    "        return {\n",
    "            \"full_network_nodes\": total_size,\n",
    "            \"largest_component_nodes\": component_size,\n",
    "            \"full_network_edges\": total_edges,\n",
    "            \"largest_component_edges\": component_edges,\n",
    "            \"coverage_ratio_nodes\": component_size / total_size if total_size > 0 else 0,\n",
    "            \"coverage_ratio_edges\": component_edges / total_edges if total_edges > 0 else 0\n",
    "        }\n",
    "    \n",
    "    def visualize_network(self, G, output_path, title=None):\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # 计算布局 - 使用spring_layout但调整参数以获得更好的可视化效果\n",
    "        pos = nx.spring_layout(G, k=0.15, iterations=50, seed=42)  # 添加seed保证可重复性\n",
    "        \n",
    "        # 绘制节点（按入度大小调整）\n",
    "        in_degrees = dict(G.in_degree())\n",
    "        node_sizes = [in_degrees[n] * 50 + 10 for n in G.nodes()]\n",
    "        \n",
    "        # 添加节点颜色基于聚类系数\n",
    "        clustering = nx.clustering(G.to_undirected())\n",
    "        node_colors = [clustering[n] for n in G.nodes()]  # 使用聚类系数作为颜色\n",
    "        \n",
    "        nodes = nx.draw_networkx_nodes(\n",
    "            G, pos,\n",
    "            node_size=node_sizes,\n",
    "            node_color=node_colors,\n",
    "            cmap=plt.cm.viridis,  # 使用颜色映射\n",
    "            alpha=0.8,\n",
    "            vmin=0, vmax=1  # 聚类系数范围0-1\n",
    "        )\n",
    "        \n",
    "        # 添加颜色条\n",
    "        plt.colorbar(nodes, label='Clustering Coefficient')\n",
    "        \n",
    "        # 绘制边（按权重调整）\n",
    "        edge_widths = [d.get('weight', 1) * 0.8 for _, _, d in G.edges(data=True)]\n",
    "        \n",
    "        nx.draw_networkx_edges(\n",
    "            G, pos,\n",
    "            width=edge_widths,\n",
    "            edge_color='gray',\n",
    "            arrowsize=10,  # 调小箭头大小\n",
    "            arrowstyle='->'\n",
    "        )\n",
    "        \n",
    "        # 只标注重要节点（避免图像过于拥挤）\n",
    "        important_nodes = [n for n in G.nodes() if in_degrees[n] > np.percentile(list(in_degrees.values()), 90)]\n",
    "        labels = {n: n for n in important_nodes}\n",
    "        nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "        \n",
    "        # 设置标题\n",
    "        if title is None:\n",
    "            title = \"Patent Citation Network (Cited → Citing)\"\n",
    "        plt.title(title, fontsize=14)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def get_largest_component(self, G):\n",
    "        \"\"\"获取最大弱连通子图\"\"\"\n",
    "        undirected = G.to_undirected()\n",
    "        largest_cc_nodes = max(nx.connected_components(undirected), key=len)\n",
    "        return G.subgraph(largest_cc_nodes).copy()\n",
    "    \n",
    "    def save_network_data(self, G, largest_cc, output_folder):\n",
    "        \"\"\"保存完整网络和最大子图到CSV\"\"\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # 保存完整网络\n",
    "        full_edges = [\n",
    "            {\"Source\": u, \"Target\": v, \"Weight\": d['weight']}\n",
    "            for u, v, d in G.edges(data=True)\n",
    "        ]\n",
    "        pd.DataFrame(full_edges).to_csv(\n",
    "            os.path.join(output_folder, 'full_network.csv'),\n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # 保存最大连通子图\n",
    "        lcc_edges = [\n",
    "            {\"Source\": u, \"Target\": v, \"Weight\": d['weight']}\n",
    "            for u, v, d in largest_cc.edges(data=True)\n",
    "        ]\n",
    "        pd.DataFrame(lcc_edges).to_csv(\n",
    "            os.path.join(output_folder, 'largest_component.csv'),\n",
    "            index=False\n",
    "        )\n",
    "    \n",
    "    def save_node_metrics(self, G, output_folder):\n",
    "        \"\"\"计算节点指标（包含聚类系数）\"\"\"\n",
    "        metrics = []\n",
    "        \n",
    "        # 预先计算全局指标\n",
    "        global_eff = nx.global_efficiency(G.to_undirected())\n",
    "        betweenness = nx.betweenness_centrality(G)\n",
    "        closeness = nx.closeness_centrality(G) if nx.is_strongly_connected(G) else {n:0 for n in G.nodes()}\n",
    "        clustering = nx.clustering(G.to_undirected())  # 计算聚类系数\n",
    "        \n",
    "        # 获取所有连通组件（优化性能，避免重复计算）\n",
    "        undirected = G.to_undirected()\n",
    "        components = {n: c for c in nx.connected_components(undirected) for n in c}\n",
    "        total_nodes = len(G.nodes())\n",
    "\n",
    "        for node in G.nodes():\n",
    "            # 计算该节点所在连通子图的连接度\n",
    "            component_size = len(components[node])\n",
    "            connectivity = component_size / total_nodes if total_nodes > 0 else 0\n",
    "\n",
    "            metrics.append({\n",
    "                'PatentNumber': node,\n",
    "                'InDegree': G.in_degree(node),\n",
    "                'OutDegree': G.out_degree(node),\n",
    "                'TotalDegree': G.in_degree(node) + G.out_degree(node),\n",
    "                'GlobalEfficiency': global_eff,\n",
    "                'BetweennessCentrality': betweenness.get(node, 0),\n",
    "                'ClosenessCentrality': closeness.get(node, 0),\n",
    "                'ClusteringCoefficient': clustering.get(node, 0),  # 新增聚类系数\n",
    "                'ComponentSize': component_size,          # 所在连通子图的节点数\n",
    "                'Connectivity': round(connectivity, 4)    # 连接度百分比\n",
    "            })\n",
    "\n",
    "        # 保存到CSV\n",
    "        pd.DataFrame(metrics).to_csv(\n",
    "            os.path.join(output_folder, 'node_metrics.csv'),\n",
    "            index=False\n",
    "        )\n",
    "        print(f\"节点指标已保存到: {output_folder}\")\n",
    "\n",
    "# 实际调用示例\n",
    "if __name__ == '__main__':\n",
    "    # 创建处理器实例\n",
    "    processor = PatentProcessor()\n",
    "    \n",
    "    # 设置输入输出路径（根据实际情况修改）\n",
    "    input_folder = 'data'  # 包含专利txt文件的文件夹\n",
    "    output_folder = input_folder+'-results'  # 结果输出文件夹\n",
    "    \n",
    "    # 执行处理流程\n",
    "    print(\"=== 开始处理专利数据 ===\")\n",
    "    processor.process_folder(input_folder, output_folder)\n",
    "    \n",
    "    print(\"\\n=== 开始分析引用网络 ===\")\n",
    "    stats = processor.analyze_networks(output_folder)\n",
    "    \n",
    "    print(\"\\n处理完成！所有结果已保存到\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d99b169-6198-4712-9c64-a1e8889b3984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cudf\n",
      "  Downloading cudf-0.6.1.post1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: cudf\n",
      "  Building wheel for cudf (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[30 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m /opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m installing to build/bdist.linux-x86_64/wheel\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/var/tmp/pip-install-iwq2hntm/cudf_40ac568a1174473abab399bba1aca97b/setup.py\", line 18, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name=pkg,\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/__init__.py\", line 155, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 148, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 163, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 967, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/wheel/_bdist_wheel.py\", line 422, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"install\")\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 313, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/pytorch/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 986, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/var/tmp/pip-install-iwq2hntm/cudf_40ac568a1174473abab399bba1aca97b/setup.py\", line 15, in run\n",
      "  \u001b[31m   \u001b[0m     raise Exception(long_description)\n",
      "  \u001b[31m   \u001b[0m Exception: Please install cudf via the rapidsai conda channel. See https://rapids.ai/start.html for instructions.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for cudf\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for cudf\n",
      "Failed to build cudf\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (cudf)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ae1012-2171-4fbd-8920-0916ad7c3119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb76c6b-ebf5-46a9-80c9-02097f8f5891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
      "Collecting cudf-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/cudf-cu11/cudf_cu11-25.4.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask-cudf-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/dask-cudf-cu11/dask_cudf_cu11-25.4.0-py3-none-any.whl (50 kB)\n",
      "Collecting cuml-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/cuml-cu11/cuml_cu11-25.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (9.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cugraph-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/cugraph-cu11/cugraph_cu11-25.4.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nx-cugraph-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/nx-cugraph-cu11/nx_cugraph_cu11-25.4.0-py3-none-any.whl (166 kB)\n",
      "Collecting cuspatial-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/cuspatial-cu11/cuspatial_cu11-25.4.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cuproj-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/cuproj-cu11/cuproj_cu11-25.4.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (850 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m850.2/850.2 kB\u001b[0m \u001b[31m266.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cuxfilter-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/cuxfilter-cu11/cuxfilter_cu11-25.4.0-py3-none-any.whl (83 kB)\n",
      "Collecting cucim-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/cucim-cu11/cucim_cu11-25.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m178.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pylibraft-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/pylibraft-cu11/pylibraft_cu11-25.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (836 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m836.4/836.4 kB\u001b[0m \u001b[31m274.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting raft-dask-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/raft-dask-cu11/raft_dask_cu11-25.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (288.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cuvs-cu11==25.4.*\n",
      "  Downloading https://pypi.nvidia.com/cuvs-cu11/cuvs_cu11-25.4.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (729 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m729.9/729.9 kB\u001b[0m \u001b[31m269.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cachetools in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (5.5.2)\n",
      "Collecting cubinlinker-cu11 (from cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/cubinlinker-cu11/cubinlinker_cu11-0.3.0.post3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m176.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cuda-python<12.0a0,>=11.8.5 (from cudf-cu11==25.4.*)\n",
      "  Downloading cuda_python-11.8.7-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting cupy-cuda11x>=12.0.0 (from cudf-cu11==25.4.*)\n",
      "  Downloading cupy_cuda11x-13.4.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (2025.3.0)\n",
      "Collecting libcudf-cu11==25.4.* (from cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/libcudf-cu11/libcudf_cu11-25.4.0-py3-none-manylinux_2_28_x86_64.whl (434.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 MB\u001b[0m \u001b[31m159.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numba-cuda<0.5.0a0,>=0.4.0 (from cudf-cu11==25.4.*)\n",
      "  Downloading numba_cuda-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numba<0.62.0a0,>=0.59.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (0.61.0)\n",
      "Requirement already satisfied: numpy<3.0a0,>=1.23 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (1.26.4)\n",
      "Collecting nvtx>=0.2.1 (from cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/nvtx/nvtx-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (473 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (24.2)\n",
      "Requirement already satisfied: pandas<2.2.4dev0,>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (2.2.3)\n",
      "Collecting ptxcompiler-cu11 (from cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/ptxcompiler-cu11/ptxcompiler_cu11-0.8.1.post3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m179.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow<20.0.0a0,>=14.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (19.0.1)\n",
      "Collecting pylibcudf-cu11==25.4.* (from cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/pylibcudf-cu11/pylibcudf_cu11-25.4.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (26.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.8/26.8 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (13.4.2)\n",
      "Collecting rmm-cu11==25.4.* (from cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/rmm-cu11/rmm_cu11-25.4.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m314.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cudf-cu11==25.4.*) (4.12.2)\n",
      "Collecting pynvml<13.0.0a0,>=12.0.0 (from dask-cudf-cu11==25.4.*)\n",
      "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting rapids-dask-dependency==25.4.* (from dask-cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-25.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting dask-cuda==25.4.* (from cuml-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/dask-cuda/dask_cuda-25.4.0-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cuml-cu11==25.4.*) (1.4.2)\n",
      "Collecting libcuml-cu11==25.4.* (from cuml-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/libcuml-cu11/libcuml_cu11-25.4.0-py3-none-manylinux_2_28_x86_64.whl (312.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 MB\u001b[0m \u001b[31m156.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numba<0.62.0a0,>=0.59.1 (from cudf-cu11==25.4.*)\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu11 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cuml-cu11==25.4.*) (11.10.3.66)\n",
      "Collecting nvidia-cufft-cu11 (from cuml-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cufft-cu11/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m146.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11 (from cuml-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-curand-cu11/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11 (from cuml-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cusolver-cu11/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m134.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11 (from cuml-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-cusparse-cu11/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m137.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cuml-cu11==25.4.*) (1.15.2)\n",
      "Collecting treelite==4.4.1 (from cuml-cu11==25.4.*)\n",
      "  Downloading treelite-4.4.1-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting libcugraph-cu11==25.4.* (from cugraph-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/libcugraph-cu11/libcugraph_cu11-25.4.1-py3-none-manylinux_2_28_x86_64.whl (1101.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 GB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pylibcugraph-cu11==25.4.* (from cugraph-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/pylibcugraph-cu11/pylibcugraph_cu11-25.4.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m203.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ucx-py-cu11==0.43.* (from cugraph-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/ucx-py-cu11/ucx_py_cu11-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m281.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=3.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nx-cugraph-cu11==25.4.*) (3.4.2)\n",
      "Requirement already satisfied: geopandas>=1.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cuspatial-cu11==25.4.*) (1.0.1)\n",
      "Collecting libcuspatial-cu11==25.4.* (from cuspatial-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/libcuspatial-cu11/libcuspatial_cu11-25.4.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting bokeh<=3.6.3,>=3.1 (from cuxfilter-cu11==25.4.*)\n",
      "  Downloading bokeh-3.6.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting datashader>=0.15 (from cuxfilter-cu11==25.4.*)\n",
      "  Downloading datashader-0.18.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting holoviews>=1.16.0 (from cuxfilter-cu11==25.4.*)\n",
      "  Downloading holoviews-1.20.2-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting jupyter-server-proxy (from cuxfilter-cu11==25.4.*)\n",
      "  Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting panel>=1.0 (from cuxfilter-cu11==25.4.*)\n",
      "  Downloading panel-1.7.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: shapely<2.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cuxfilter-cu11==25.4.*) (2.0.7)\n",
      "Requirement already satisfied: click in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cucim-cu11==25.4.*) (8.1.8)\n",
      "Collecting lazy-loader>=0.4 (from cucim-cu11==25.4.*)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting scikit-image<0.26.0a0,>=0.19.0 (from cucim-cu11==25.4.*)\n",
      "  Downloading scikit_image-0.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting libraft-cu11==25.4.* (from pylibraft-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/libraft-cu11/libraft_cu11-25.4.0-py3-none-manylinux_2_28_x86_64.whl (18.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/18.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting distributed-ucxx-cu11==0.43.* (from raft-dask-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/distributed-ucxx-cu11/distributed_ucxx_cu11-0.43.0-py3-none-any.whl (25 kB)\n",
      "Collecting libcuvs-cu11==25.4.* (from cuvs-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/libcuvs-cu11/libcuvs_cu11-25.4.0-py3-none-manylinux_2_28_x86_64.whl (990.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.8/990.8 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting zict>=2.0.0 (from dask-cuda==25.4.*->cuml-cu11==25.4.*)\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
      "Collecting ucxx-cu11==0.43.* (from distributed-ucxx-cu11==0.43.*->raft-dask-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/ucxx-cu11/ucxx_cu11-0.43.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (717 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.2/717.2 kB\u001b[0m \u001b[31m282.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libkvikio-cu11==25.4.* (from libcudf-cu11==25.4.*->cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/libkvikio-cu11/libkvikio_cu11-25.4.0-py3-none-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting librmm-cu11==25.4.* (from libcudf-cu11==25.4.*->cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/librmm-cu11/librmm_cu11-25.4.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvcomp-cu11==4.2.0.11 (from libcudf-cu11==25.4.*->cudf-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/nvidia-nvcomp-cu11/nvidia_nvcomp_cu11-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl (30.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.9/30.9 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rapids-logger==0.1.* (from libcudf-cu11==25.4.*->cudf-cu11==25.4.*)\n",
      "  Downloading rapids_logger-0.1.1-py3-none-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting dask==2025.2.0 (from rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*)\n",
      "  Downloading dask-2025.2.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting distributed==2025.2.0 (from rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*)\n",
      "  Downloading distributed-2025.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting libucx-cu11<1.19,>=1.15.0 (from ucx-py-cu11==0.43.*->cugraph-cu11==25.4.*)\n",
      "  Downloading libucx_cu11-1.18.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (3.1.1)\n",
      "Collecting partd>=1.4.0 (from dask==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (1.0.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from dask==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (8.6.1)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (3.1.6)\n",
      "Collecting locket>=1.0.0 (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (1.1.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (5.9.3)\n",
      "Collecting sortedcontainers>=2.0.5 (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tblib>=1.6.0 (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*)\n",
      "  Downloading tblib-3.1.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (6.4.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (1.26.20)\n",
      "Collecting libucxx-cu11==0.43.* (from ucxx-cu11==0.43.*->distributed-ucxx-cu11==0.43.*->raft-dask-cu11==25.4.*)\n",
      "  Downloading https://pypi.nvidia.com/libucxx-cu11/libucxx_cu11-0.43.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (506 kB)\n",
      "Requirement already satisfied: contourpy>=1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bokeh<=3.6.3,>=3.1->cuxfilter-cu11==25.4.*) (1.3.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bokeh<=3.6.3,>=3.1->cuxfilter-cu11==25.4.*) (11.1.0)\n",
      "Collecting xyzservices>=2021.09.1 (from bokeh<=3.6.3,>=3.1->cuxfilter-cu11==25.4.*)\n",
      "  Downloading xyzservices-2025.4.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting cuda-bindings~=11.8.7 (from cuda-python<12.0a0,>=11.8.5->cudf-cu11==25.4.*)\n",
      "  Downloading cuda_bindings-11.8.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cupy-cuda11x>=12.0.0->cudf-cu11==25.4.*) (0.8.3)\n",
      "Collecting colorcet (from datashader>=0.15->cuxfilter-cu11==25.4.*)\n",
      "  Downloading colorcet-3.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting multipledispatch (from datashader>=0.15->cuxfilter-cu11==25.4.*)\n",
      "  Downloading multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting param (from datashader>=0.15->cuxfilter-cu11==25.4.*)\n",
      "  Downloading param-2.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pyct (from datashader>=0.15->cuxfilter-cu11==25.4.*)\n",
      "  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from datashader>=0.15->cuxfilter-cu11==25.4.*) (2.28.2)\n",
      "Collecting xarray (from datashader>=0.15->cuxfilter-cu11==25.4.*)\n",
      "  Downloading xarray-2025.4.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (3.11.14)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from geopandas>=1.0.0->cuspatial-cu11==25.4.*) (0.10.0)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from geopandas>=1.0.0->cuspatial-cu11==25.4.*) (3.7.1)\n",
      "Collecting pyviz-comms>=2.1 (from holoviews>=1.16.0->cuxfilter-cu11==25.4.*)\n",
      "  Downloading pyviz_comms-3.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba<0.62.0a0,>=0.59.1->cudf-cu11==25.4.*)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu11==25.4.*) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu11==25.4.*) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pandas<2.2.4dev0,>=2.0->cudf-cu11==25.4.*) (2025.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from panel>=1.0->cuxfilter-cu11==25.4.*) (6.2.0)\n",
      "Requirement already satisfied: linkify-it-py in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from panel>=1.0->cuxfilter-cu11==25.4.*) (2.0.3)\n",
      "Requirement already satisfied: markdown in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from panel>=1.0->cuxfilter-cu11==25.4.*) (3.8)\n",
      "Requirement already satisfied: markdown-it-py in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from panel>=1.0->cuxfilter-cu11==25.4.*) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from panel>=1.0->cuxfilter-cu11==25.4.*) (0.4.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from panel>=1.0->cuxfilter-cu11==25.4.*) (4.65.2)\n",
      "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml<13.0.0a0,>=12.0.0->dask-cudf-cu11==25.4.*)\n",
      "  Downloading nvidia_ml_py-12.575.51-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting imageio!=2.35.0,>=2.33 (from scikit-image<0.26.0a0,>=0.19.0->cucim-cu11==25.4.*)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image<0.26.0a0,>=0.19.0->cucim-cu11==25.4.*)\n",
      "  Downloading tifffile-2025.5.10-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: jupyter-server>=1.24.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server-proxy->cuxfilter-cu11==25.4.*) (2.15.0)\n",
      "Collecting simpervisor>=1.0.0 (from jupyter-server-proxy->cuxfilter-cu11==25.4.*)\n",
      "  Downloading simpervisor-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server-proxy->cuxfilter-cu11==25.4.*) (5.14.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11->cuml-cu11==25.4.*) (60.2.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nvidia-cublas-cu11->cuml-cu11==25.4.*) (0.45.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from rich->cudf-cu11==25.4.*) (2.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.6.0->cugraph-cu11==25.4.*) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2>=2.10.3->distributed==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (3.0.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (4.9.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (26.3.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.8.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from markdown-it-py->panel>=1.0->cuxfilter-cu11==25.4.*) (0.1.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from pyogrio>=0.7.2->geopandas>=1.0.0->cuspatial-cu11==25.4.*) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<2.2.4dev0,>=2.0->cudf-cu11==25.4.*) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bleach->panel>=1.0->cuxfilter-cu11==25.4.*) (0.5.1)\n",
      "Requirement already satisfied: uc-micro-py in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from linkify-it-py->panel>=1.0->cuxfilter-cu11==25.4.*) (1.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->datashader>=0.15->cuxfilter-cu11==25.4.*) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests->datashader>=0.15->cuxfilter-cu11==25.4.*) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (21.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from importlib_metadata>=4.13.0->dask==2025.2.0->rapids-dask-dependency==25.4.*->dask-cudf-cu11==25.4.*) (3.21.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-client>=7.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-client>=7.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.6.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (4.3.7)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (4.23.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (2.0.7)\n",
      "Requirement already satisfied: referencing in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.36.2)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (4.13.3)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.5.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from terminado>=0.8.3->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.7.0)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (0.24.0)\n",
      "Requirement already satisfied: fqdn in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (2.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu11==25.4.*) (2.9.0.20241206)\n",
      "Downloading treelite-4.4.1-py3-none-manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.8/922.8 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dask-2025.2.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distributed-2025.2.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapids_logger-0.1.1-py3-none-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (192 kB)\n",
      "Downloading bokeh-3.6.3-py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m145.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cuda_python-11.8.7-py3-none-any.whl (11 kB)\n",
      "Downloading cupy_cuda11x-13.4.1-cp310-cp310-manylinux2014_x86_64.whl (99.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datashader-0.18.1-py3-none-any.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m174.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading holoviews-1.20.2-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m147.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba_cuda-0.4.0-py3-none-any.whl (453 kB)\n",
      "Downloading panel-1.7.1-py3-none-any.whl (29.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m158.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
      "Downloading scikit_image-0.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m162.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_server_proxy-4.4.0-py3-none-any.whl (37 kB)\n",
      "Downloading cuda_bindings-11.8.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m161.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading libucx_cu11-1.18.1-py3-none-manylinux_2_28_x86_64.whl (27.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.6/27.6 MB\u001b[0m \u001b[31m164.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m146.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_ml_py-12.575.51-py3-none-any.whl (47 kB)\n",
      "Downloading param-2.2.0-py3-none-any.whl (119 kB)\n",
      "Downloading pyviz_comms-3.0.4-py3-none-any.whl (83 kB)\n",
      "Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
      "Downloading tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
      "Downloading xyzservices-2025.4.0-py3-none-any.whl (90 kB)\n",
      "Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Downloading colorcet-3.1.0-py3-none-any.whl (260 kB)\n",
      "Downloading multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading xarray-2025.4.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading tblib-3.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: sortedcontainers, ptxcompiler-cu11, nvtx, nvidia-ml-py, multipledispatch, libkvikio-cu11, cuda-bindings, zict, xyzservices, tifffile, tblib, simpervisor, rapids-logger, pynvml, param, nvidia-nvcomp-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, locket, llvmlite, libucx-cu11, lazy-loader, imageio, cupy-cuda11x, cuda-python, cubinlinker-cu11, colorcet, ucx-py-cu11, treelite, scikit-image, pyviz-comms, pyct, partd, nvidia-cusolver-cu11, numba, librmm-cu11, cuproj-cu11, xarray, rmm-cu11, numba-cuda, libucxx-cu11, libraft-cu11, libcudf-cu11, dask, cucim-cu11, bokeh, ucxx-cu11, pylibraft-cu11, pylibcudf-cu11, panel, libcuvs-cu11, libcuspatial-cu11, libcugraph-cu11, distributed, datashader, rapids-dask-dependency, pylibcugraph-cu11, libcuml-cu11, holoviews, cuvs-cu11, cudf-cu11, nx-cugraph-cu11, distributed-ucxx-cu11, dask-cudf-cu11, dask-cuda, cuspatial-cu11, raft-dask-cu11, jupyter-server-proxy, cuml-cu11, cugraph-cu11, cuxfilter-cu11\n",
      "  Attempting uninstall: nvidia-ml-py\n",
      "    Found existing installation: nvidia-ml-py 11.495.46\n",
      "    Uninstalling nvidia-ml-py-11.495.46:\n",
      "      Successfully uninstalled nvidia-ml-py-11.495.46\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.44.0\n",
      "    Uninstalling llvmlite-0.44.0:\n",
      "      Successfully uninstalled llvmlite-0.44.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.61.0\n",
      "    Uninstalling numba-0.61.0:\n",
      "      Successfully uninstalled numba-0.61.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gpustat 1.0.0 requires nvidia-ml-py<=11.495.46,>=11.450.129, but you have nvidia-ml-py 12.575.51 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bokeh-3.6.3 colorcet-3.1.0 cubinlinker-cu11-0.3.0.post3 cucim-cu11-25.4.0 cuda-bindings-11.8.7 cuda-python-11.8.7 cudf-cu11-25.4.0 cugraph-cu11-25.4.1 cuml-cu11-25.4.0 cuproj-cu11-25.4.0 cupy-cuda11x-13.4.1 cuspatial-cu11-25.4.0 cuvs-cu11-25.4.0 cuxfilter-cu11-25.4.0 dask-2025.2.0 dask-cuda-25.4.0 dask-cudf-cu11-25.4.0 datashader-0.18.1 distributed-2025.2.0 distributed-ucxx-cu11-0.43.0 holoviews-1.20.2 imageio-2.37.0 jupyter-server-proxy-4.4.0 lazy-loader-0.4 libcudf-cu11-25.4.0 libcugraph-cu11-25.4.1 libcuml-cu11-25.4.0 libcuspatial-cu11-25.4.0 libcuvs-cu11-25.4.0 libkvikio-cu11-25.4.0 libraft-cu11-25.4.0 librmm-cu11-25.4.0 libucx-cu11-1.18.1 libucxx-cu11-0.43.0 llvmlite-0.43.0 locket-1.0.0 multipledispatch-1.0.0 numba-0.60.0 numba-cuda-0.4.0 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-ml-py-12.575.51 nvidia-nvcomp-cu11-4.2.0.11 nvtx-0.2.12 nx-cugraph-cu11-25.4.0 panel-1.7.1 param-2.2.0 partd-1.4.2 ptxcompiler-cu11-0.8.1.post3 pyct-0.5.0 pylibcudf-cu11-25.4.0 pylibcugraph-cu11-25.4.1 pylibraft-cu11-25.4.0 pynvml-12.0.0 pyviz-comms-3.0.4 raft-dask-cu11-25.4.0 rapids-dask-dependency-25.4.0 rapids-logger-0.1.1 rmm-cu11-25.4.0 scikit-image-0.25.2 simpervisor-1.0.0 sortedcontainers-2.4.0 tblib-3.1.0 tifffile-2025.5.10 treelite-4.4.1 ucx-py-cu11-0.43.0 ucxx-cu11-0.43.0 xarray-2025.4.0 xyzservices-2025.4.0 zict-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --extra-index-url=https://pypi.nvidia.com \"cudf-cu11==25.4.*\" \"dask-cudf-cu11==25.4.*\" \"cuml-cu11==25.4.*\" \"cugraph-cu11==25.4.*\" \"nx-cugraph-cu11==25.4.*\" \"cuspatial-cu11==25.4.*\" \"cuproj-cu11==25.4.*\" \"cuxfilter-cu11==25.4.*\" \"cucim-cu11==25.4.*\" \"pylibraft-cu11==25.4.*\" \"raft-dask-cu11==25.4.*\" \"cuvs-cu11==25.4.*\" \"nx-cugraph-cu11==25.4.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532a057-71f1-40f8-bef6-1e25b122c866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
